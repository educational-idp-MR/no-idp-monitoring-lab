# Etapa 3 â€“ ExperimentaciÃ³n y AnÃ¡lisis del Comportamiento del Sistema

## Objetivo
Analizar el comportamiento real de la aplicaciÃ³n usando el dashboard construido en Grafana, identificar patrones, anomalÃ­as o comportamientos inesperados, y reflexionar sobre posibles causas basadas Ãºnicamente en las mÃ©tricas y logs observados.

Como parte de esta etapa, si detectas comportamientos anÃ³malos en algÃºn endpoint, deberÃ¡s **intentar corregirlos modificando el cÃ³digo de la aplicaciÃ³n** y luego observar cÃ³mo cambian las mÃ©tricas despuÃ©s del ajuste.

---

## 1. PreparaciÃ³n del entorno

1. Abre tu dashboard en Grafana.  
2. Verifica que la aplicaciÃ³n estÃ© corriendo.  
3. Genera trÃ¡fico hacia la API utilizando el mÃ©todo que prefieras:
   - navegador  
   - Postman  
   - `curl`  

Ejecuta solicitudes de distintos tipos y frecuencias. Tu objetivo es observar cÃ³mo responde la aplicaciÃ³n bajo distintos patrones de uso.

---

## 2. ObservaciÃ³n guiada: explorando el comportamiento del sistema

Mientras realizas experimentos con la aplicaciÃ³n, analiza cÃ³mo reaccionan los paneles de tu dashboard. Usa estas preguntas como guÃ­a :

### 2.1. TrÃ¡fico y carga
- Â¿La tasa de solicitudes se incrementa cuando envÃ­as varias peticiones seguidas?  
- Â¿Hay endpoints que muestran comportamientos distintos bajo la misma carga?

### 2.2. Rendimiento
- Â¿La latencia se mantiene estable o presenta variaciones?  
- Â¿Los picos de latencia coinciden con momentos de mayor trÃ¡fico?

### 2.3. Errores
- Â¿Aparecen errores en la visualizaciÃ³n de cÃ³digos HTTP?  
- Â¿Se concentran en determinados endpoints?  
- Â¿Coinciden temporalmente con algo en los logs?

### 2.4. Logs
Con el panel de logs basado en Loki:
- Filtra por nivel (`INFO`, `WARN`, `ERROR`).  
- Â¿Se observan mensajes repetitivos?  
- Â¿Los logs te ayudan a interpretar picos o caÃ­das en las mÃ©tricas?

---

## 3. IdentificaciÃ³n de relaciones causaâ€“efecto

Intenta correlacionar lo que ves:

- TrÃ¡fico - Latencia  
- Latencia - Errores  
- Errores - Mensajes en los logs  
- Logs - Patrones en los endpoints  

Ajusta el rango de tiempo para observar con mÃ¡s detalle (Ãºltimos 5 minutos, 15 minutos, 1 hora), para hacerlo puedes seleccionar una ventana de tiempo directamente sobre las visualizaciones de grafana en caso que quieras hacer "Zoom" sobre un Ã¡rea especÃ­fica o con las opciones fijas del dashboard.

---

## 4. DetecciÃ³n de anomalÃ­as y puntos de interÃ©s

Durante tu experimentaciÃ³n, presta atenciÃ³n a:

- Picos de latencia inesperados  
- Tiempos de respuesta inconsistentes  
- Errores HTTP en momentos especÃ­ficos  
- Repentinas caÃ­das o aumentos de trÃ¡fico  
- Logs con mensajes atÃ­picos o en cantidades inusuales  
- Endpoints cuyos valores no cambian como esperarÃ­as  

Reflexiona:

- Â¿QuÃ© valores parecen normales?  
- Â¿QuÃ© te llama la atenciÃ³n?  
- Â¿QuÃ© panel te alertÃ³ primero?  
- Â¿CÃ³mo lo confirmaste?

---

## 5. *Tarea adicional*: Intento de correcciÃ³n de anomalÃ­as

Si en tu anÃ¡lisis detectas **anomalÃ­as persistentes** en algÃºn endpoint (variaciones en la latencia, errores frecuentes, respuestas inesperadas, etc.):

### âœï¸ 5.1. PropÃ³n una posible causa  
BasÃ¡ndote en las mÃ©tricas y en los logs, escribe una hipÃ³tesis.  
Por ejemplo:  
- â€œEste endpoint parece mÃ¡s lento que los demÃ¡s porqueâ€¦â€  
- â€œLos errores aumentan cuando hago este tipo de solicitudesâ€¦â€  

### ğŸ› ï¸ 5.2. Modifica el cÃ³digo  
Revisa el cÃ³digo de la aplicaciÃ³n y realiza un pequeÃ±o ajuste que creas que podrÃ­a mitigar o corregir el comportamiento observado:  
- mejorar validaciones  
- ajustar lÃ³gica interna  
- refactorizar un fragmento  
- mover cÃ¡lculos  
- corregir una condiciÃ³n  
- optimizar manipulaciÃ³n de datos  
- mejorar manejo de excepciones  

*No detectar con: lo importante es aplicar el mÃ©todo cientÃ­fico â†’ observar, formular hipÃ³tesis, intervenir y volver a observar.)*

### 5.3. Despliega la aplicaciÃ³n nuevamente  
Compila, ejecuta y genera trÃ¡fico otra vez hacia el endpoint.

### 5.4. Observa cÃ³mo cambia la mÃ©trica  
Â¿El ajuste surtiÃ³ efecto?  
- Â¿La latencia cambiÃ³?  
- Â¿Los errores disminuyeron?  
- Â¿Los logs muestran un comportamiento mÃ¡s estable?  

Registra tus observaciones.

---

## 6. Registro de observaciones

En tu bitÃ¡cora del laboratorio documenta:

1. **Valores observados**  : Incluye una foto con: 
   - Tiempos de respuesta  
   - Tasas de solicitudes  
   - Errores  
   - AnomalÃ­as detectadas  

2. **Correlaciones**  
   - QuÃ© paneles se relacionan entre sÃ­  
   - QuÃ© mÃ©tricas cambiaron al mismo tiempo  

3. **AnomalÃ­as detectadas**  
   - CuÃ¡ndo ocurrieron  
   - CÃ³mo se identificaron:
        - QuÃ© viste en el dashboard  
        - QuÃ© viste en los logs  

4. **IntervenciÃ³n (si aplica)**  
   - HipÃ³tesis inicial sobre la causa  
   - Ajuste realizado en el cÃ³digo  
   - Impacto despuÃ©s del cambio  (Imagen  y analisis del estado del dashboard posterior al ajuste)

5. **ReflexiÃ³n final**  
   - Â¿QuÃ© panel te resultÃ³ mÃ¡s Ãºtil para detectar problemas?  
   - Â¿QuÃ© mÃ©trica aporta mayor valor para monitorear un sistema real?  
   - Â¿QuÃ© agregarÃ­as o mejorarÃ­as en tu dashboard?

---

## 7. ConclusiÃ³n de la etapa

En esta etapa has utilizado mÃ©tricas y logs como herramientas fundamentales para comprender el comportamiento de un sistema en ejecuciÃ³n.  
TambiÃ©n aplicaste un proceso iterativo de anÃ¡lisis y correcciÃ³n, muy similar al que se usa en entornos reales de observabilidad, donde los dashboards son clave para detectar problemas y validar mejoras.

